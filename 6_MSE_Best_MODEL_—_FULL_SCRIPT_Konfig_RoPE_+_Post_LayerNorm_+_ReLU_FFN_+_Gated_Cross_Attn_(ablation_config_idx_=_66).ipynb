{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMgi6OmJsEwrCfsSryvKxqB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emrealty/AlertProject/blob/main/6_MSE_Best_MODEL_%E2%80%94_FULL_SCRIPT_Konfig_RoPE_%2B_Post_LayerNorm_%2B_ReLU_FFN_%2B_Gated_Cross_Attn_(ablation_config_idx_%3D_66).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef2QiwPDqRpr",
        "outputId": "ac35df70-9722-4279-ddd7-fe70dbc886e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 1) Ortam Kurulumu ve Drive Bağlantısı =====\n",
            "Mounted at /content/drive\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement rdkit-pypi (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for rdkit-pypi\u001b[0m\u001b[31m\n",
            "\u001b[0mKullanılan cihaz: cuda\n",
            "\n",
            "===== 2) Veri Okuma ve İnceleme =====\n",
            "DataFrame ilk 5 satır:\n",
            "         ID        Target                                             SMILES  \\\n",
            "0  11314340          AAK1  CC1=C2C=C(C=CC2=NN1)C3=CC(=CN=C3)OCC(CC4=CC=CC...   \n",
            "1  11314340   ABL1(E255K)  CC1=C2C=C(C=CC2=NN1)C3=CC(=CN=C3)OCC(CC4=CC=CC...   \n",
            "2  11314340   ABL1(F317I)  CC1=C2C=C(C=CC2=NN1)C3=CC(=CN=C3)OCC(CC4=CC=CC...   \n",
            "3  11314340  ABL1(F317I)p  CC1=C2C=C(C=CC2=NN1)C3=CC(=CN=C3)OCC(CC4=CC=CC...   \n",
            "4  11314340   ABL1(F317L)  CC1=C2C=C(C=CC2=NN1)C3=CC(=CN=C3)OCC(CC4=CC=CC...   \n",
            "\n",
            "                                            Sequence     Label  \n",
            "0  MKKFFDSRREQGGSGLGSGSSGGGGSTSGLGSGYIGRVFGIGRQQV...  7.366532  \n",
            "1  PFWKILNPLLERGTYYYFMGQQPGKVLGDQRRPSLPALHFIKGAGK...  5.000000  \n",
            "2  PFWKILNPLLERGTYYYFMGQQPGKVLGDQRRPSLPALHFIKGAGK...  5.000000  \n",
            "3  PFWKILNPLLERGTYYYFMGQQPGKVLGDQRRPSLPALHFIKGAGK...  5.000000  \n",
            "4  PFWKILNPLLERGTYYYFMGQQPGKVLGDQRRPSLPALHFIKGAGK...  5.000000  \n",
            "\n",
            "Veri boyutu: (30056, 5)\n",
            "Label istatistikleri:\n",
            "count    30056.000000\n",
            "mean         5.451535\n",
            "std          0.894717\n",
            "min          5.000000\n",
            "25%          5.000000\n",
            "50%          5.000000\n",
            "75%          5.522879\n",
            "max         10.795880\n",
            "Name: Label, dtype: float64\n",
            "\n",
            "===== 3) Train-Val-Test Split =====\n",
            "Train: (24044, 5) Val: (3006, 5) Test: (3006, 5)\n",
            "\n",
            "===== 4) Tokenizasyon, Dataset, DataLoader =====\n",
            "\n",
            "SMILES Tokenizer Testi:\n",
            "  Input: CCCCl\n",
            "  Tokens: ['C', 'C', 'C', 'Cl']  (Beklenen: ['C','C','C','Cl'])\n",
            "  Input: c1ccccc1Br\n",
            "  Tokens: ['c', '1', 'c', 'c', 'c', 'c', 'c', '1', 'Br']\n",
            "\n",
            "✅ Protein vocab size: 25\n",
            "✅ SMILES vocab size:  27\n",
            "   SMILES vocab'da 'Cl' var mı? True\n",
            "   SMILES vocab'da 'Br' var mı? True\n",
            "train_loader: 24044 örnek, val_loader: 3006, test_loader: 3006\n",
            "\n",
            "===== 5) Model (RoPE + Post-LN + Gated Cross-Attn) =====\n",
            "\n",
            "===== 7) MSE_Best: Eğitim & Değerlendirme =====\n",
            "\n",
            "--- MSE_Best_RoPE_PostLN_ReLU_Gated ---\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 01/20 TrainLoss=1.3176 ValLoss=0.7127 ValRMSE=0.8443 (104.9s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 02/20 TrainLoss=0.7399 ValLoss=0.6068 ValRMSE=0.7791 (103.4s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 03/20 TrainLoss=0.6544 ValLoss=0.5758 ValRMSE=0.7589 (103.4s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 04/20 TrainLoss=0.6089 ValLoss=0.5249 ValRMSE=0.7246 (103.3s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 05/20 TrainLoss=0.5671 ValLoss=0.4885 ValRMSE=0.6990 (103.4s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 06/20 TrainLoss=0.5327 ValLoss=0.5045 ValRMSE=0.7103 (103.4s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 07/20 TrainLoss=0.4865 ValLoss=0.4523 ValRMSE=0.6726 (103.4s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 08/20 TrainLoss=0.4626 ValLoss=0.4652 ValRMSE=0.6821 (103.4s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 09/20 TrainLoss=0.4353 ValLoss=0.3845 ValRMSE=0.6202 (103.4s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 10/20 TrainLoss=0.4177 ValLoss=0.3829 ValRMSE=0.6189 (103.4s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 11/20 TrainLoss=0.4073 ValLoss=0.3633 ValRMSE=0.6028 (103.5s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 12/20 TrainLoss=0.3945 ValLoss=0.4094 ValRMSE=0.6399 (103.4s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 13/20 TrainLoss=0.3781 ValLoss=0.4358 ValRMSE=0.6602 (103.3s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 14/20 TrainLoss=0.3675 ValLoss=0.4456 ValRMSE=0.6676 (103.3s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 15/20 TrainLoss=0.3602 ValLoss=0.3700 ValRMSE=0.6083 (103.5s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 16/20 TrainLoss=0.3497 ValLoss=0.3691 ValRMSE=0.6076 (103.4s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 17/20 TrainLoss=0.3380 ValLoss=0.3381 ValRMSE=0.5816 (103.3s)\n",
            "  -> Best model saved to best_MSE_Best_RoPE_PostLN_ReLU_Gated.pt\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 18/20 TrainLoss=0.3263 ValLoss=0.3469 ValRMSE=0.5890 (103.4s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 19/20 TrainLoss=0.3223 ValLoss=0.3872 ValRMSE=0.6223 (103.4s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Epoch 20/20 TrainLoss=0.3119 ValLoss=0.3509 ValRMSE=0.5924 (103.3s)\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Test MSE:   0.3335\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Test RMSE:  0.5776\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Test CI:    0.8377\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Test r_m^2: 0.1955\n",
            "[MSE_Best_RoPE_PostLN_ReLU_Gated] Test AUPR:  0.6435\n",
            "\n",
            "✅ MSE_Best (RoPE + post-LN + ReLU FFN + gated cross-attn) değerlendirmesi tamamlandı.\n"
          ]
        }
      ],
      "source": [
        "###########################################\n",
        "# MSE_Best MODEL — FULL SCRIPT\n",
        "# Konfig: RoPE + Post-LayerNorm + ReLU FFN + Gated Cross-Attn\n",
        "# (ablation: config_idx = 66)\n",
        "###########################################\n",
        "\n",
        "######################\n",
        "# [BÖLÜM 1: Ortam Kurulumu, Drive, Paketler]\n",
        "######################\n",
        "print(\"===== 1) Ortam Kurulumu ve Drive Bağlantısı =====\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install rdkit-pypi -q\n",
        "!pip install torch -q\n",
        "!pip install transformers -q\n",
        "!pip install scikit-learn -q\n",
        "!pip install pandas -q\n",
        "!pip install numpy -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, average_precision_score\n",
        "from math import sqrt\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Kullanılan cihaz:\", device)\n",
        "\n",
        "######################\n",
        "# [BÖLÜM 2: Veri Yükleme ve İnceleme]\n",
        "######################\n",
        "print(\"\\n===== 2) Veri Okuma ve İnceleme =====\")\n",
        "\n",
        "# Burada davis benzeri bir CSV var. Yolunu gerekirse güncelle!\n",
        "file_path = '/content/drive/MyDrive/TransformDTA/davis_cleaned.csv'\n",
        "\n",
        "df = pd.read_csv(file_path, sep=',', header=0)\n",
        "\n",
        "# Sütunları (ID, Target, SMILES, Sequence, Label) olarak rename\n",
        "df.rename(columns={\n",
        "    \"Compound_ID\": \"ID\",\n",
        "    \"Protein_ID\": \"Target\",\n",
        "    \"SMILES\": \"SMILES\",\n",
        "    \"Protein_Sequence\": \"Sequence\",\n",
        "    \"Label\": \"Label\"\n",
        "}, inplace=True)\n",
        "\n",
        "print(\"DataFrame ilk 5 satır:\")\n",
        "print(df.head())\n",
        "print(\"\\nVeri boyutu:\", df.shape)\n",
        "print(\"Label istatistikleri:\")\n",
        "print(df['Label'].describe())\n",
        "\n",
        "######################\n",
        "# [BÖLÜM 3: Train / Val / Test Split]\n",
        "######################\n",
        "print(\"\\n===== 3) Train-Val-Test Split =====\")\n",
        "\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape, \"Test:\", test_df.shape)\n",
        "\n",
        "######################\n",
        "# [BÖLÜM 4: Tokenizasyon ve PyTorch Dataset/DataLoader]\n",
        "######################\n",
        "print(\"\\n===== 4) Tokenizasyon, Dataset, DataLoader =====\")\n",
        "\n",
        "# Protein tokenizasyonu (karakter düzeyinde)\n",
        "def tokenize_protein(seq):\n",
        "    return list(seq.strip())\n",
        "\n",
        "# SMILES tokenizasyonu (Cl, Br vb. iki harfli öğelerle)\n",
        "_SMILES_REGEX = re.compile(\n",
        "    r\"\\[\\w+\\]|\"       # [NH3+], [O-]\n",
        "    r\"\\%\\d{2}|\"       # yüzük kapama %12\n",
        "    r\"Br|Cl|\"         # iki harfli elementler\n",
        "    r\"Si|Se|Na|Li|Mg|Ca|Zn|Fe|Cu|Mn|Al|Ag|Sn|Hg|Pb|Bi|Ne|He|Ar|Kr|Xe|\"\n",
        "    r\"@@?|\"           # stereo\n",
        "    r\"=|#|\"           # bağlar\n",
        "    r\"\\(|\\)|\"         # parantez\n",
        "    r\"\\.|\"            # nokta\n",
        "    r\"\\d|\"            # rakam\n",
        "    r\"[A-Za-z]|\"      # tek harf element\n",
        "    r\"\\+|\\-|\\*|\\/|\\\\\" # işaretler\n",
        ")\n",
        "\n",
        "def tokenize_smiles(smi: str):\n",
        "    return _SMILES_REGEX.findall(smi.strip())\n",
        "\n",
        "# Test\n",
        "print(f\"\\nSMILES Tokenizer Testi:\")\n",
        "test_smiles = \"CCCCl\"\n",
        "print(f\"  Input: {test_smiles}\")\n",
        "print(f\"  Tokens: {tokenize_smiles(test_smiles)}  (Beklenen: ['C','C','C','Cl'])\")\n",
        "test_smiles2 = \"c1ccccc1Br\"\n",
        "print(f\"  Input: {test_smiles2}\")\n",
        "print(f\"  Tokens: {tokenize_smiles(test_smiles2)}\")\n",
        "\n",
        "# Vocab\n",
        "all_prot_tokens = set()\n",
        "for seq in train_df['Sequence']:\n",
        "    all_prot_tokens.update(tokenize_protein(seq))\n",
        "\n",
        "all_smi_tokens = set()\n",
        "for smi in train_df['SMILES']:\n",
        "    all_smi_tokens.update(tokenize_smiles(smi))\n",
        "\n",
        "prot_special_tokens = ['<pad>', '<unk>', '<cls>', '<sep>']\n",
        "smi_special_tokens  = ['<pad>', '<unk>', '<cls>', '<sep>']\n",
        "\n",
        "prot_vocab_list = prot_special_tokens + sorted(list(all_prot_tokens))\n",
        "smi_vocab_list  = smi_special_tokens + sorted(list(all_smi_tokens))\n",
        "\n",
        "protein_vocab = {token: idx for idx, token in enumerate(prot_vocab_list)}\n",
        "smiles_vocab  = {token: idx for idx, token in enumerate(smi_vocab_list)}\n",
        "\n",
        "print(f\"\\n✅ Protein vocab size: {len(protein_vocab)}\")\n",
        "print(f\"✅ SMILES vocab size:  {len(smiles_vocab)}\")\n",
        "print(f\"   SMILES vocab'da 'Cl' var mı? {'Cl' in smiles_vocab}\")\n",
        "print(f\"   SMILES vocab'da 'Br' var mı? {'Br' in smiles_vocab}\")\n",
        "\n",
        "class DTADataset(Dataset):\n",
        "    def __init__(self, df, protein_vocab, smiles_vocab,\n",
        "                 max_prot_len=1000, max_smi_len=100):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.protein_vocab = protein_vocab\n",
        "        self.smiles_vocab  = smiles_vocab\n",
        "        self.max_prot_len  = max_prot_len\n",
        "        self.max_smi_len   = max_smi_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        seq = row['Sequence']\n",
        "        smi = row['SMILES']\n",
        "        label = float(row['Label'])\n",
        "\n",
        "        prot_toks = tokenize_protein(seq)[:self.max_prot_len]\n",
        "        smi_toks  = tokenize_smiles(smi)[:self.max_smi_len]\n",
        "\n",
        "        prot_ids = [self.protein_vocab.get(t, self.protein_vocab['<unk>']) for t in prot_toks]\n",
        "        smi_ids  = [self.smiles_vocab.get(t, self.smiles_vocab['<unk>']) for t in smi_toks]\n",
        "\n",
        "        prot_pad_len = self.max_prot_len - len(prot_ids)\n",
        "        smi_pad_len  = self.max_smi_len - len(smi_ids)\n",
        "\n",
        "        prot_ids += [self.protein_vocab['<pad>']] * prot_pad_len\n",
        "        smi_ids  += [self.smiles_vocab['<pad>']] * smi_pad_len\n",
        "\n",
        "        return {\n",
        "            'protein_input': torch.tensor(prot_ids, dtype=torch.long),\n",
        "            'smiles_input':  torch.tensor(smi_ids,  dtype=torch.long),\n",
        "            'label':         torch.tensor(label,   dtype=torch.float)\n",
        "        }\n",
        "\n",
        "batch_size = 32\n",
        "train_dataset = DTADataset(train_df, protein_vocab, smiles_vocab)\n",
        "val_dataset   = DTADataset(val_df,   protein_vocab, smiles_vocab)\n",
        "test_dataset  = DTADataset(test_df,  protein_vocab, smiles_vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"train_loader: {len(train_dataset)} örnek, val_loader: {len(val_dataset)}, test_loader: {len(test_dataset)}\")\n",
        "\n",
        "######################\n",
        "# [BÖLÜM 5: MODEL — RoPE + Post-LN + ReLU FFN + Gated Cross-Attn]\n",
        "######################\n",
        "print(\"\\n===== 5) Model (RoPE + Post-LN + Gated Cross-Attn) =====\")\n",
        "\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    RoPE için basit rotary embedding.\n",
        "    head_dim üzerinden sin/cos tabanlı faz döndürme uygular.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, base=10000):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        self.register_buffer('inv_freq', inv_freq)\n",
        "\n",
        "    def forward(self, seq_len, device=None):\n",
        "        if device is None:\n",
        "            device = self.inv_freq.device\n",
        "        t = torch.arange(seq_len, device=device, dtype=torch.float)  # [L]\n",
        "        freqs = torch.einsum('i,j->ij', t, self.inv_freq)           # [L, dim/2]\n",
        "        emb = torch.cat((freqs, freqs), dim=-1)                     # [L, dim]\n",
        "        cos = emb.cos()[None, :, None, :]                           # [1,L,1,dim]\n",
        "        sin = emb.sin()[None, :, None, :]\n",
        "        return cos, sin\n",
        "\n",
        "def apply_rotary_pos_emb(x, cos, sin):\n",
        "    \"\"\"\n",
        "    x:   [B, L, H, D]\n",
        "    cos: [1, L, 1, D]\n",
        "    sin: [1, L, 1, D]\n",
        "    \"\"\"\n",
        "    D = x.size(-1)\n",
        "    x1 = x[..., : D//2]\n",
        "    x2 = x[..., D//2:]\n",
        "    cos_half = cos[..., : D//2]\n",
        "    sin_half = sin[..., : D//2]\n",
        "    x_rot_first = x1 * cos_half - x2 * sin_half\n",
        "    x_rot_second = x1 * sin_half + x2 * cos_half\n",
        "    return torch.cat([x_rot_first, x_rot_second], dim=-1)\n",
        "\n",
        "class RoPESelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    RoPE kullanan Multi-Head Self-Attention\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, nhead, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % nhead == 0\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.head_dim = d_model // nhead\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, d_model)\n",
        "        self.k_proj = nn.Linear(d_model, d_model)\n",
        "        self.v_proj = nn.Linear(d_model, d_model)\n",
        "        self.o_proj = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.rotary = RotaryEmbedding(self.head_dim)\n",
        "\n",
        "    def forward(self, x, key_padding_mask=None):\n",
        "        # x: [B, L, D]\n",
        "        B, L, D = x.shape\n",
        "        H = self.nhead\n",
        "\n",
        "        q = self.q_proj(x).view(B, L, H, self.head_dim)\n",
        "        k = self.k_proj(x).view(B, L, H, self.head_dim)\n",
        "        v = self.v_proj(x).view(B, L, H, self.head_dim)\n",
        "\n",
        "        cos, sin = self.rotary(L, x.device)\n",
        "        q = apply_rotary_pos_emb(q, cos, sin)\n",
        "        k = apply_rotary_pos_emb(k, cos, sin)\n",
        "\n",
        "        q = q.permute(0, 2, 1, 3)  # [B,H,L,Dh]\n",
        "        k = k.permute(0, 2, 1, 3)\n",
        "        v = v.permute(0, 2, 1, 3)\n",
        "\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)  # [B,H,L,L]\n",
        "        if key_padding_mask is not None:\n",
        "            # key_padding_mask: [B, L], True = pad\n",
        "            mask = key_padding_mask[:, None, None, :]  # [B,1,1,L]\n",
        "            attn_scores = attn_scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        attn_probs = self.dropout(attn_probs)\n",
        "\n",
        "        attn_out = torch.matmul(attn_probs, v)  # [B,H,L,Dh]\n",
        "        attn_out = attn_out.permute(0, 2, 1, 3).contiguous().view(B, L, D)\n",
        "        out = self.o_proj(attn_out)\n",
        "        return out\n",
        "\n",
        "class RoPECrossAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    RoPE kullanan Multi-Head Cross-Attention\n",
        "    (q ve k tarafına ayrı rotary uygulanıyor)\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, nhead, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % nhead == 0\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.head_dim = d_model // nhead\n",
        "\n",
        "        self.q_proj = nn.Linear(d_model, d_model)\n",
        "        self.k_proj = nn.Linear(d_model, d_model)\n",
        "        self.v_proj = nn.Linear(d_model, d_model)\n",
        "        self.o_proj = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.rotary_q = RotaryEmbedding(self.head_dim)\n",
        "        self.rotary_k = RotaryEmbedding(self.head_dim)\n",
        "\n",
        "    def forward(self, q_input, kv_input, kv_mask=None):\n",
        "        # q_input: [B, Lq, D], kv_input: [B, Lk, D]\n",
        "        B, Lq, D = q_input.shape\n",
        "        Lk = kv_input.size(1)\n",
        "        H = self.nhead\n",
        "\n",
        "        q = self.q_proj(q_input).view(B, Lq, H, self.head_dim)\n",
        "        k = self.k_proj(kv_input).view(B, Lk, H, self.head_dim)\n",
        "        v = self.v_proj(kv_input).view(B, Lk, H, self.head_dim)\n",
        "\n",
        "        cos_q, sin_q = self.rotary_q(Lq, q_input.device)\n",
        "        cos_k, sin_k = self.rotary_k(Lk, kv_input.device)\n",
        "        q = apply_rotary_pos_emb(q, cos_q, sin_q)\n",
        "        k = apply_rotary_pos_emb(k, cos_k, sin_k)\n",
        "\n",
        "        q = q.permute(0, 2, 1, 3)  # [B,H,Lq,Dh]\n",
        "        k = k.permute(0, 2, 1, 3)  # [B,H,Lk,Dh]\n",
        "        v = v.permute(0, 2, 1, 3)  # [B,H,Lk,Dh]\n",
        "\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)  # [B,H,Lq,Lk]\n",
        "        if kv_mask is not None:\n",
        "            mask = kv_mask[:, None, None, :]  # [B,1,1,Lk]\n",
        "            attn_scores = attn_scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        attn_probs = self.dropout(attn_probs)\n",
        "\n",
        "        attn_out = torch.matmul(attn_probs, v)  # [B,H,Lq,Dh]\n",
        "        attn_out = attn_out.permute(0, 2, 1, 3).contiguous().view(B, Lq, D)\n",
        "        out = self.o_proj(attn_out)\n",
        "        return out\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    - Self-Attention: RoPE\n",
        "    - FFN: ReLU MLP\n",
        "    - Normalizasyon: Post-LayerNorm\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model=256, nhead=8, dim_feedforward=1024, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = RoPESelfAttention(d_model, nhead, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_feedforward),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim_feedforward, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, key_padding_mask=None):\n",
        "        attn_out = self.self_attn(x, key_padding_mask=key_padding_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_out))\n",
        "        ff = self.ffn(x)\n",
        "        x = self.norm2(x + ff)\n",
        "        return x\n",
        "\n",
        "class CrossAttentionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Protein ↔ SMILES arası Cross-Attention\n",
        "    - RoPE\n",
        "    - Gated residual (attn_type = gated)\n",
        "    - Post-LayerNorm\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model=256, nhead=8, dropout=0.1, gated=True):\n",
        "        super().__init__()\n",
        "        self.cross_attn_p2s = RoPECrossAttention(d_model, nhead, dropout)\n",
        "        self.cross_attn_s2p = RoPECrossAttention(d_model, nhead, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm_p = nn.LayerNorm(d_model)\n",
        "        self.norm_s = nn.LayerNorm(d_model)\n",
        "        self.gated = gated\n",
        "        if gated:\n",
        "            self.gate_p = nn.Linear(d_model, d_model)\n",
        "            self.gate_s = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, p, s, p_mask=None, s_mask=None):\n",
        "        # p: protein [B,Lp,D], s: smiles [B,Ls,D]\n",
        "\n",
        "        # Protein, SMILES'e dikkat eder\n",
        "        p2 = self.cross_attn_p2s(p, s, kv_mask=s_mask)\n",
        "        if self.gated:\n",
        "            gate_p = torch.sigmoid(self.gate_p(p))\n",
        "            p = self.norm_p(p + self.dropout(gate_p * p2))\n",
        "        else:\n",
        "            p = self.norm_p(p + self.dropout(p2))\n",
        "\n",
        "        # SMILES, Protein'e dikkat eder\n",
        "        s2 = self.cross_attn_s2p(s, p, kv_mask=p_mask)\n",
        "        if self.gated:\n",
        "            gate_s = torch.sigmoid(self.gate_s(s))\n",
        "            s = self.norm_s(s + self.dropout(gate_s * s2))\n",
        "        else:\n",
        "            s = self.norm_s(s + self.dropout(s2))\n",
        "\n",
        "        return p, s\n",
        "\n",
        "class CrossAttentionFusionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    MSE-best Ablasyon Mimari:\n",
        "    - Positional Encoding: RoPE (token embedding + rotary, ekstra pos emb yok)\n",
        "    - Normalizasyon: Post-LayerNorm\n",
        "    - FFN: ReLU MLP\n",
        "    - Cross-Attn: Gated RoPE Cross-Attn\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 prot_vocab_size,\n",
        "                 smi_vocab_size,\n",
        "                 prot_max_len=1000,\n",
        "                 smi_max_len=100,\n",
        "                 d_model=256,\n",
        "                 nhead=8,\n",
        "                 num_encoder_layers=2,\n",
        "                 num_cross_layers=1,\n",
        "                 dim_feedforward=1024,\n",
        "                 dropout=0.1,\n",
        "                 padding_idx=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.padding_idx = padding_idx\n",
        "\n",
        "        # Sadece token embedding (pozisyon bilgisi RoPE ile atn içinde)\n",
        "        self.prot_token_emb = nn.Embedding(prot_vocab_size, d_model, padding_idx=padding_idx)\n",
        "        self.smi_token_emb  = nn.Embedding(smi_vocab_size,  d_model, padding_idx=padding_idx)\n",
        "\n",
        "        # Encoder blokları\n",
        "        self.prot_encoders = nn.ModuleList([\n",
        "            TransformerEncoderBlock(d_model, nhead, dim_feedforward, dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "        self.smi_encoders = nn.ModuleList([\n",
        "            TransformerEncoderBlock(d_model, nhead, dim_feedforward, dropout)\n",
        "            for _ in range(num_encoder_layers)\n",
        "        ])\n",
        "\n",
        "        # Gated Cross-Attn katmanları\n",
        "        self.cross_layers = nn.ModuleList([\n",
        "            CrossAttentionBlock(d_model, nhead, dropout, gated=True)\n",
        "            for _ in range(num_cross_layers)\n",
        "        ])\n",
        "\n",
        "        # Çıkış başlığı\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(d_model*2, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, prot_in, smi_in):\n",
        "        # Maskeler\n",
        "        prot_mask = (prot_in == self.padding_idx)   # [B,Lp]\n",
        "        smi_mask  = (smi_in  == self.padding_idx)   # [B,Ls]\n",
        "\n",
        "        # Embedding\n",
        "        p_embed = self.prot_token_emb(prot_in)      # [B,Lp,D]\n",
        "        s_embed = self.smi_token_emb(smi_in)        # [B,Ls,D]\n",
        "\n",
        "        # Encoder katmanları\n",
        "        for enc in self.prot_encoders:\n",
        "            p_embed = enc(p_embed, key_padding_mask=prot_mask)\n",
        "        for enc in self.smi_encoders:\n",
        "            s_embed = enc(s_embed, key_padding_mask=smi_mask)\n",
        "\n",
        "        # Gated Cross-Attn katmanları\n",
        "        for cross in self.cross_layers:\n",
        "            p_embed, s_embed = cross(p_embed, s_embed, p_mask=prot_mask, s_mask=smi_mask)\n",
        "\n",
        "        # Masked mean pooling\n",
        "        prot_mask_expanded = prot_mask.unsqueeze(-1).expand_as(p_embed)\n",
        "        smi_mask_expanded  = smi_mask.unsqueeze(-1).expand_as(s_embed)\n",
        "\n",
        "        p_sum = (p_embed * (~prot_mask_expanded)).sum(dim=1)\n",
        "        p_cnt = (~prot_mask).sum(dim=1, keepdim=True).clamp(min=1)\n",
        "        p_vec = p_sum / p_cnt\n",
        "\n",
        "        s_sum = (s_embed * (~smi_mask_expanded)).sum(dim=1)\n",
        "        s_cnt = (~smi_mask).sum(dim=1, keepdim=True).clamp(min=1)\n",
        "        s_vec = s_sum / s_cnt\n",
        "\n",
        "        out = self.fc(torch.cat([p_vec, s_vec], dim=1)).squeeze(-1)\n",
        "        return out\n",
        "\n",
        "######################\n",
        "# [BÖLÜM 6: Eğitim / Değerlendirme Fonksiyonları ve Metrikler]\n",
        "######################\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        prot_in = batch['protein_input'].to(device)\n",
        "        smi_in  = batch['smiles_input'].to(device)\n",
        "        labels  = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(prot_in, smi_in)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    preds, trues = [], []\n",
        "    for batch in dataloader:\n",
        "        prot_in = batch['protein_input'].to(device)\n",
        "        smi_in  = batch['smiles_input'].to(device)\n",
        "        labels  = batch['label'].to(device)\n",
        "        outputs = model(prot_in, smi_in)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        preds.extend(outputs.detach().cpu().numpy())\n",
        "        trues.extend(labels.detach().cpu().numpy())\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss, np.array(preds), np.array(trues)\n",
        "\n",
        "def concordance_index(y_true, y_pred):\n",
        "    n, n_conc = 0, 0\n",
        "    for i in range(len(y_true)):\n",
        "        for j in range(i+1, len(y_true)):\n",
        "            if y_true[i] != y_true[j]:\n",
        "                n += 1\n",
        "                if (y_true[i] > y_true[j] and y_pred[i] > y_pred[j]) or \\\n",
        "                   (y_true[i] < y_true[j] and y_pred[i] < y_pred[j]):\n",
        "                    n_conc += 1\n",
        "    return 0 if n == 0 else n_conc / n\n",
        "\n",
        "def rm2_score(y_true, y_pred):\n",
        "    r, _ = pearsonr(y_true, y_pred)\n",
        "    r_sq = r**2\n",
        "    denom = np.sum(y_true*y_true) - len(y_true)*(np.mean(y_true)**2)\n",
        "    if abs(denom) < 1e-8:\n",
        "        return 0.0\n",
        "    slope = (np.sum(y_true*y_pred) - len(y_true)*np.mean(y_true)*np.mean(y_pred)) / denom\n",
        "    intercept = np.mean(y_pred) - slope*np.mean(y_true)\n",
        "    y_pred_reg = slope*y_true + intercept\n",
        "    r0, _ = pearsonr(y_true, y_pred_reg)\n",
        "    r0_sq = r0**2\n",
        "    return r_sq * (1 - np.sqrt(abs(r_sq - r0_sq)))\n",
        "\n",
        "def aupr_score(y_true, y_pred, threshold=7.0):\n",
        "    labels_bin = np.array([1 if val > threshold else 0 for val in y_true])\n",
        "    return average_precision_score(labels_bin, y_pred)\n",
        "\n",
        "######################\n",
        "# [BÖLÜM 7: MSE_Best MODEL — Eğitim & Değerlendirme]\n",
        "######################\n",
        "print(\"\\n===== 7) MSE_Best: Eğitim & Değerlendirme =====\")\n",
        "\n",
        "common_cfg = dict(\n",
        "    prot_vocab_size=len(protein_vocab),\n",
        "    smi_vocab_size=len(smiles_vocab),\n",
        "    prot_max_len=1000,\n",
        "    smi_max_len=100,\n",
        "    d_model=256,\n",
        "    nhead=8,\n",
        "    num_encoder_layers=2,\n",
        "    num_cross_layers=1,\n",
        "    dim_feedforward=1024,\n",
        "    dropout=0.1,\n",
        "    padding_idx=0\n",
        ")\n",
        "\n",
        "EPOCHS = 20\n",
        "LR = 1e-4\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "name = \"MSE_Best_RoPE_PostLN_ReLU_Gated\"\n",
        "print(f\"\\n--- {name} ---\")\n",
        "set_seed(42)  # tekrarlanabilirlik\n",
        "model = CrossAttentionFusionModel(**common_cfg).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_path = f\"best_{name}.pt\"\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    t0 = time.time()\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_preds, val_trues = evaluate(model, val_loader, criterion, device)\n",
        "    val_rmse = sqrt(mean_squared_error(val_trues, val_preds))\n",
        "    dt = time.time() - t0\n",
        "    print(f\"[{name}] Epoch {epoch:02d}/{EPOCHS} \"\n",
        "          f\"TrainLoss={train_loss:.4f} ValLoss={val_loss:.4f} ValRMSE={val_rmse:.4f} ({dt:.1f}s)\")\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        print(f\"  -> Best model saved to {best_path}\")\n",
        "\n",
        "# Test: en iyi checkpoint ile\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "test_loss, test_preds, test_trues = evaluate(model, test_loader, criterion, device)\n",
        "test_rmse = sqrt(mean_squared_error(test_trues, test_preds))\n",
        "test_ci   = concordance_index(test_trues, test_preds)\n",
        "test_rm2  = rm2_score(test_trues, test_preds)\n",
        "test_aupr = aupr_score(test_trues, test_preds, threshold=7.0)\n",
        "\n",
        "print(f\"[{name}] Test MSE:   {test_loss:.4f}\")\n",
        "print(f\"[{name}] Test RMSE:  {test_rmse:.4f}\")\n",
        "print(f\"[{name}] Test CI:    {test_ci:.4f}\")\n",
        "print(f\"[{name}] Test r_m^2: {test_rm2:.4f}\")\n",
        "print(f\"[{name}] Test AUPR:  {test_aupr:.4f}\")\n",
        "\n",
        "print(\"\\n✅ MSE_Best (RoPE + post-LN + ReLU FFN + gated cross-attn) değerlendirmesi tamamlandı.\")\n"
      ]
    }
  ]
}